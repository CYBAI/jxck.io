# [unicode][javascript] JavaScript に置ける文字コードと「文字数」の扱い方

## Intro

Twitter の 140 文字制限のように、 JS で文字数を数えたい場合がある。
多言語対応なども踏まえた上で、どのように処理するのが正しいのか。
もしくは `.length` を数えるだけではダメな理由を、文字コードや JS の内部表現の話を踏まえて解説する。


## 1 文字とは何か

Unicode は全ての文字に ID を振ることを目的としている。

例えば `🐟` (FISH)  なら `0x1F41F` だ。

1 つの文字に 1 つの ID が割り当てられているのだから、文字の数を数える場合は、この ID の数を数えれば良いと考えることができるだろう。おおよその場合はそれで良い。

例えば `𩸽定食🐟` という文字列を、それぞれ ID の配列に変換するとこうなる。

```
“𩸽定食🐟” // [0x29E3D, 0xDE3D, 0x5B9A, 0x1F41F]
```

ID が 4 つあるので `𩸽定食🐟` は 4 文字だと考えることができる。

**この ID のことを Unicode では Code Point という**


## 文字の伝達

### UTF-32

データとして文字を相手に送る際に、この Code Point が利用できる。
例えば `🐟` を送るには、 `0x1F41F` という Code Point が相手に伝われば良いのだ。

単純に考えれば、この Code Point をバイナリデータとしてそのまま送れば良いだろう。

Code Point はおおよそ 4byte あれば収まるので 32bit のデータとして送ることができる。

TODO: UTF-32 の結果

受け取った側は、データを 32bit づつ Code Point とみなして文字に置き換えていけば良いし、受け取ったバイト数を 4 で割れば文字の数もわかる。

このように 32bit づつ送るという発想が、 UTF-32 と呼ばれる方式の中核だ。


### UTF-16

UTF-32 なら Code Point がそのまま入ってるので非常にシンプルだが、よく使う文字はそこまで大きな Code Point が振られてないため、ほとんどが 0 になる。

そこで、 Code Point を 32bit ではなく、半分の 16bit で表し、 16bit に収まらない Code Point は 32bit で表す方式にすれば、同じ文字列をぐっと小さいサイズで送ることができる。


この 16bit で送るという発想が、 UTF-16 と呼ばれる方式の中核だ。

ただし、この瞬間から文字数はバイト列の長さだけではわからなくなってしまった、つまり可変長になってしまったのである。

我々が普段使ってる文字の多くは 16bit に収まる。が、 16bit 1 つに収まらず 2 つ必要になる文字もある。

例えば鯖という文字は
9BD6
1001,1011,1101,0110 0x9BD6 39894

𩸽
29E3D
0010,1001,1110,0011,1101 0x29E3D 171581

この 2byte に収まらず 4byte で表す文字は、  **サロゲートペア** と呼ばれる。

もし、幸運にも文字列の中にサロゲートペアが 1 つも入っていなければ、バイト列を単純に 2 で割れば文字数が出る。しかし 1 つでもサロゲートペアがあると、単純な割り算では本来よりも多くの文字数があるように見えてしまうのだ。


### UTF-8

英数字(a-zA-Z0-9) など、いわゆるアスキー文字と呼ばれるものは、 Code Point の中でも小さい値が割り当てられている。
これら Code Point は 8bit の範囲に収まっているので、 16 bit で表すと無駄が出てくる。

そこで、 8bit で表せる Code Point は 8bit で、足らないものは 16bit で、さらに足らないものは 24bit で、、と「小さい Code Point はより小さく」表せば、英語のみのテキストなどはさらに小さく表すことができる。

この 8bit を最小とし、それ以外を必要に応じて 2, 3, 4byte と可変長で表す発想が UTF-8 と呼ばれる方式の中核だ。



## JS の内部表現

さて、 JS で以下の処理を実行した場合、 “a” のデータがメモリ上に保存されるわけだが、このデータは Code Point がそのまま保存されているわけではない。

```js
var char = “a”
```

JS の内部表現は UTF-16 であるため、メモリに保存された文字列は Code Point を 2byte or 4byte で表したもの配列になっている。


ここで注意したいのは、ここで UTF-16 が選ばれるのは JS の仕様であって、 JS ファイルのエンコーディングとは関係ない。
HTML/CSS/JS ファイルは、 UTF-8 が使われることが最も多いが、それによって内部の表現が UTF-8 になったりはしないということだ。

イメージとしては、ブラウザは JS ファイルのレスポンスを受けた際、 Content-Encoding ヘッダなどによってファイルを解釈し、そこから Code Point を割り出す。代入された値が “a” であることを知ったら、それをメモリ上に UTF-16 で保存する。 JS ファイルが Shift-JIS であっても同じだ。

これを聞くと JS が UTF-16 であれば、その変換オーバーヘッドが無いのでは? と思うかもしれないが、レガシーシステムとの連携などを考えなければ、 UTF-8 以外を使う必要は基本的にないので気にしないで良い。


ともあれ、このメモリ上に保存された値は **Code Point そのもの** ではなく、その Code Point を UTF-16 つまり、 16bit で表現し直したものなのだ。


これを踏まえた上で、 JS のプログラム上で文字列を数える処理について見ていく。


## length

length は文字数ではなく、単にこの UTF-16 配列の長さだ。
だから、 1 文字に 16bit が 2 つ必要なサロゲートペアは length が 2 となってしまう。

```js
‘鯖定食’.length === 3  // [0x9BD6, 0x5b9a, 0x98df].length
‘𩸽定食’.length === 4 // [0xD867, 0xDE3D, 0x5b9a, 0x98df].length
```

これが、文字数を数える処理に length が使えない場合があることの原因だ。
(逆を言えば、 16bit で収まる文字の範囲、例えば英数字のであると **保証** できるならば、 length を使うこともできる)

そもそも、 Code Point の数を数えたいのに、内部で保持している UTF-16 の配列を操作しているから問題なのだ。
つまり、ブラウザが内部で行なっているように、 UTF-16 の配列を、元の Unicode の Code Point の配列に戻せれば良さそうだ。

もちろん、この方法は知られている。特に、ブラウザがこれをどう行うべきかというアルゴリズムは WHATWG の仕様に書かれているため、これを実装すれば、全てのブラウザで Code Point の列が手に入る。


TODO: obtain unicode


```
‘鯖定食’ = [0x9BD6, 0x5b9a, 0x98df]
‘𩸽定食’ = [0x29E3D, 0x5b9a, 0x98df]
```


Code Point の配列にしてしまえば、少なくとも Code Point の数を数えるといった処理はそのまま length で行える。

しかし、最近はこうした処理を改善する API がブラウザ自体にあるため、使えるならそれらを使うのが良いだろう。自前で Code Point 列にするのは、それらが使えない場合にとる手段と筆者は考える。


## 正規表現

正規表現で、 `.` も 1 文字ではなく、 UTF-16  1 つを意味する。したがって、サロゲートペアがあると 1 文字にマッチせず、途中で切れる。

```js
'鯖定食'.match(/./) //["鯖"]
'𩸽定食'.match(/./) // ["�"]

'鯖定食'.match(/.{3}/) // ["鯖定食"]
'𩸽定食'.match(/.{3}/) // ["𩸽定"] 変なところで切れる
```

そこで、 ES2015 では Unicode Flag というフラグが入った。これで Code Point の単位でマッチさせることができるようになる。

```js
'鯖定食'.match(/./u) // ["鯖"]
'𩸽定食'.match(/./u) // ["𩸽"]

'鯖定食'.match(/.{3}/u) // ["鯖定食"]
'𩸽定食'.match(/.{3}/u) // ["𩸽定食"]
```


## split

文字列を文字の配列に分解するのに使われる `split(‘’)` も、サロゲートペアがあると崩れてしまう。

```js
'鯖定食'.split('') === ["鯖", "定", "食"]
‘𩸽定食'.split('') === ["�", "�", "定", "食"]
```

代わりに、先ほどの Unicod フラグを使った正規表現を使うと、正しく文字の配列に分解できる。

```js
'鯖定食'.match(/./ug) // ["鯖", "定", "食"]
'𩸽定食'.match(/./ug) // ["𩸽", "定", "食"]
```


## for in / for of

繰り返し処理も注意が必要だ。特に文字列に対する添え字アクセスは、 UTF-16 配列に対するアクセスだとイメージするとわかりやすい。(ちなみに `charAt()` も同じだ)

```js
'鯖定食'[0] === "鯖"
'鯖定食'.charAt(0) === "鯖"

'𩸽定食'[0] === "�"
'𩸽定食'.charAt(0) === "�"
```

よって 1 文字ずつ処理をするという処理に for を使う場合は、添え字を基準にすることができない。

```js
const str = '鯖定食'
for (const i in str) console.log(str[i])
// 鯖
// 定
// 食

const str = ‘𩸽定食’
for (const i in str) console.log(str[i])
// �
// �
// 定
// 食
```
`for (i = 0; i < str.length; i ++)` と書いても同じだ。


代わりに ES2015 で追加された `for of` を使うと、 Unicode の Code Point 単位で繰り返し処理が可能だ。

```js
for (let c of '𩸽定食') console.log(c)
// 𩸽
// 定
// 食
```

(iterator の詳細は割愛する)


## Split Operator

Split Operator を用いた分割も、 Code Point の単位で分割される。

```js
((a, b, c) => console.log(a, b, c))(...'𩸽定食') // 𩸽 定 食
```

## Destructoring

いわゆる分割代入時の分割も Code Point が意識されている。

```js
[a,b,c]='𩸽定食'
a // "𩸽"
b // "定"
c // "食"
```

## Array.of

文字列から、文字の配列に分割するのは、 split operator と Array.of を合わせるのが一番簡単だろう。

```js
Array.of(...'𩸽定食') // ["𩸽", "定", "食"]
```

## charCode/codePoint

`charCodeAt()` は文字コードを取り、 `fromCharCode()` はその逆を行う。
𩸽の方は前半のバイトしかないため、元に戻らない。


```js
'鯖定食'.charCodeAt(0) === 0x9BD6
'𩸽定食'.charCodeAt(0) === 0xD867

String.fromCharCode('鯖'.charCodeAt(0)) //"鯖"
String.fromCharCode('𩸽'.charCodeAt(0)) // "�"
``

これも、 Code Point を取り出すメソッドが定義されている。
これならサロゲートペアである𩸽もうまく扱えることがわかるだろう。

```js
'𩸽定食'.codePointAt(0) // 0x9BD6
'鯖定食'.codePointAt(0) // 0x29E3D

String.fromCodePoint('鯖'.codePointAt(0)) // "鯖"
String.fromCodePoint('𩸽'.codePointAt(0)) // "𩸽"
```





## まとめ

文字には Code Point が割り当てられており、「文字数を数える」とは「この Code Point を数える」こととするならば、 Code Point の配列を手に入れることができれば問題は解決する。

しかし、 JavaScript は文字列データを Code Point の配列ではなく、それを効率のために UTF-16 の配列として持っているため、単に length を取っても、文字数を得ることができない場合がある。

JavaScript の API には、この Code Point を意識した操作と、 そうでない操作があるため、それを意識して処理をすれば、正しく文字数を数えられるだろう。それでもダメなら自分で UTF-16 列を Code Point 列に変換することも可能だ。


## おまけ

ここまでは基礎であり、まだまだ厄介な問題はある。

ここまでは、「文字数を数える」という処理を「Code Point の数を数える」処理であると定義した上で話を進めた。

しかし、これでは直感に反する場合が出る。

1 つが Family 問題だ。

```js
👨‍👩‍👧‍👦

Array.of(...'👨‍👩‍👧‍👦')
["👨", "‍", "👩", "‍", "👧", "‍", "👦"]
```

この Family は、正確には “family with mother father son daughter” という名前の文字で、 4 つの顔文字が合成されてできている。家族は多様なので別の組み合わせもある。

いずれにせよ、先ほどの方法で分解すると、個々の顔と間に空の文字が見える。

これは、 Family という顔文字自体が、複数の顔文字と ZWJ という制御文字でできているからである。
この制御文字を ZWJ(ZERO WCode PointTH JOINER) といい、  ZWJ 自体も Code Point であるので、先ほどのように「文字の数を数える == Code Point の数を数える」としてしまえば、これは 顔 * 4 + ZWJ * 3 で 7 文字となる。

ここが難しいところで、おそらく多くの人間がこれを 1 文字と捉えるだろう。

つまり 1 文字を **カーソルが 1 つ移動する分** と捉えているとなると、 Code Point の数だけでなく、 ZWJ を持つ文字列も 1 文字と捉える必要が出てくる。

ZWS は顔文字だけではなく、アラビア文字などで良く使われているようだ。

ちなみに Twitter は先の Family を入れると 7 文字減る。つまり、 ZWJ も 1 文字として Code Point を数えていると推測される。

もし ZWJ で結合された文字も 1 文字と数えたい場合は、 Code Point の分割の後にさらなる結合処理が必要になるだろう。


## その他

最小限で解説するため、 BMP, UCS-2, Endian, 歴史など、この手の話題につき物な話は省いた。それらの話はものの本に譲ることとする。






## Encoder/Decoder

さて、 JS が内部で持つ UTF-16 - Unicode に着目して文字数を考えてきたが、どの文字コードであれ、文字数を数える場合はまず Unicode の Code Point に変換するという作業を行うのが良いだろう。

JS エンジン自体が文字列バイト列を握っている場合は、ここまでにあげた方法で良いが、 ArrayBuffer などの形で保持している文字列データがあり、 JS エンジン自体が UTF-16 として解釈していないデータがあった場合は、自分でその処理を行う必要がある。

これを行うのが Encoding という仕様である。主に UTF-8 以外の文字コードを UTF-8 に変換するための API だ。

あくまで UTF-8 をターゲットとしているため、エンコード時に UTF-16 を指定することはできない。よってこれを用いて
今回はあまり細かくは触れないが、知っておくと良いかもしれない。

https://encoding.spec.whatwg.org
https://triple-underscore.github.io/Encoding-ja.html



